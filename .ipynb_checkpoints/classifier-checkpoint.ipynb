{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d8db0ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.lm.preprocessing import pad_both_ends, flatten, padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.lm import KneserNeyInterpolated, Laplace, StupidBackoff\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "\n",
    "# Chat GPT\n",
    "# if len(sys.argv) > 1:\n",
    "#     file_name = sys.argv[1]\n",
    "#     print(\"File name:\", file_name)\n",
    "# else:\n",
    "#     print(\"Please provide the file name as a parameter.\")\n",
    "\n",
    "# Bonus Point\n",
    "def ngrams(sentence, n):\n",
    "    ngrams = []\n",
    "    for i in range(len(sentence) - n + 1):\n",
    "        ngrams.append(np.array([sentence[i+j] for j in range(n)]))\n",
    "    return ngrams\n",
    "\n",
    "### Preprocessing data using RegexpTokenizer: picks out sequences of alphanumeric characters as tokens and drops everything else\n",
    "def preprocess_text(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = list(map(lambda s: tokenizer.tokenize(s), text))\n",
    "    text = [ele for ele in text if ele != []]   # remove empty list\n",
    "\n",
    "    return text\n",
    "\n",
    "def test_mapping(element):\n",
    "#     test = list(pad_both_ends(element, n=2))\n",
    "    test = ngrams(test, n=2)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4bb13d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr', 'Suckling', 's', 'seat', 'a', 'comparison', 'of', 'Hartfield', 'to', 'Maple', 'Grove', 'The']\n",
      "['like', 'this', 'It', 'made', 'me', 'so', 'sorry', 'that', 'I', 'could', 'only', 'say', 'in', 'a', 'foolish']\n",
      "['herself', 'in', 'supposing', 'she', 'could', 'be', 'what', 'she', 'wanted', 'to', 'be', 'Her', 'eyes', 'were']\n",
      "['realising', 'it']\n"
     ]
    }
   ],
   "source": [
    "# Open files    \n",
    "with open('./ngram_authorship_train/austen.txt') as f:\n",
    "    austen_txt = f.readlines()\n",
    "with open('./ngram_authorship_train/dickens.txt') as f:\n",
    "    dickens_txt = f.readlines()\n",
    "with open('./ngram_authorship_train/tolstoy.txt') as f:\n",
    "    tolstoy_txt = f.readlines()\n",
    "with open('./ngram_authorship_train/wilde.txt') as f:\n",
    "    wilde_txt = f.readlines()\n",
    "    \n",
    "# preprocess\n",
    "austen_txt = preprocess_text(austen_txt)\n",
    "dickens_txt = preprocess_text(dickens_txt)\n",
    "tolstoy_txt = preprocess_text(tolstoy_txt)\n",
    "wilde_txt = preprocess_text(wilde_txt)\n",
    "\n",
    "random_state = 50\n",
    "# train test split\n",
    "austen_train, austen_test = train_test_split(austen_txt, test_size=0.1, random_state=random_state)\n",
    "dickens_train, dickens_test = train_test_split(dickens_txt, test_size=0.1, random_state=random_state)\n",
    "tolstoy_train, tolstoy_test = train_test_split(tolstoy_txt, test_size=0.1, random_state=random_state)\n",
    "wilde_train, wilde_test = train_test_split(wilde_txt, test_size=0.1, random_state=random_state)\n",
    "\n",
    "print(austen_test[0])\n",
    "print(dickens_test[0])\n",
    "print(tolstoy_test[0])\n",
    "print(wilde_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5cec4b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabs: 6854\n",
      "vocabs: 9094\n",
      "vocabs: 10573\n",
      "vocabs: 8436\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "## AUSTEN\n",
    "train, vocab = padded_everygram_pipeline(2, austen_train)\n",
    "# austen_lm = MLE(2)\n",
    "# austen_lm = KneserNeyInterpolated(order=2)\n",
    "austen_lm = StupidBackoff(order=2)\n",
    "# austen_lm = Laplace(order=2)\n",
    "austen_lm.fit(train, vocab)\n",
    "print('vocabs:',len(austen_lm.vocab))\n",
    "\n",
    "## DICKENS\n",
    "train, vocab = padded_everygram_pipeline(2, dickens_train)\n",
    "# dickens_lm = MLE(2)\n",
    "# dickens_lm = KneserNeyInterpolated(order=2)\n",
    "dickens_lm = StupidBackoff(order=2)\n",
    "# dickens_lm = Laplace(order=2)\n",
    "dickens_lm.fit(train, vocab)\n",
    "print('vocabs:',len(dickens_lm.vocab))\n",
    "\n",
    "## TOLSTOY\n",
    "train, vocab = padded_everygram_pipeline(2, tolstoy_train)\n",
    "# tolstoy_lm = MLE(2)\n",
    "# tolstoy_lm = KneserNeyInterpolated(order=2)\n",
    "tolstoy_lm = StupidBackoff(order=2)\n",
    "# tolstoy_lm = Laplace(order=2)\n",
    "tolstoy_lm.fit(train, vocab)\n",
    "print('vocabs:',len(tolstoy_lm.vocab))\n",
    "\n",
    "## WILDE\n",
    "train, vocab = padded_everygram_pipeline(2, wilde_train)\n",
    "# wilde_lm = MLE(2)\n",
    "# wilde_lm = KneserNeyInterpolated(order=2)\n",
    "wilde_lm = StupidBackoff(order=2)\n",
    "# wilde_lm = Laplace(order=2)\n",
    "wilde_lm.fit(train, vocab)\n",
    "print('vocabs:',len(wilde_lm.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fe718d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NgramCounter with 2 ngram orders and 257156 ngrams>\n",
      "<NgramCounter with 2 ngram orders and 244806 ngrams>\n",
      "<NgramCounter with 2 ngram orders and 371699 ngrams>\n",
      "<NgramCounter with 2 ngram orders and 194171 ngrams>\n"
     ]
    }
   ],
   "source": [
    "print(austen_lm.counts)\n",
    "print(dickens_lm.counts)\n",
    "print(tolstoy_lm.counts)\n",
    "print(wilde_lm.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3c140383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. family: 70\n",
      "no. family: 34\n",
      "no. family: 45\n",
      "no. family: 31\n"
     ]
    }
   ],
   "source": [
    "print('no. family:', austen_lm.counts['family'])\n",
    "print('no. family:', dickens_lm.counts['family'])\n",
    "print('no. family:', tolstoy_lm.counts['family'])\n",
    "print('no. family:', wilde_lm.counts['family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "93f2a459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. family may: 0\n",
      "no. family may: 0\n",
      "no. family may: 0\n",
      "no. family may: 0\n"
     ]
    }
   ],
   "source": [
    "print('no. family may:', austen_lm.counts[['family']]['may'])\n",
    "print('no. family may:', dickens_lm.counts[['family']]['may'])\n",
    "print('no. family may:', tolstoy_lm.counts[['family']]['may'])\n",
    "print('no. family may:', wilde_lm.counts[['family']]['may'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0f7d9b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "family score: 0.0005244074196158341\n",
      "family score: 0.0002675964330969565\n",
      "family score: 0.0002330410825535088\n",
      "family score: 0.0003076220813114624\n"
     ]
    }
   ],
   "source": [
    "print('family score:',austen_lm.score('family'))\n",
    "print('family score:',dickens_lm.score('family'))\n",
    "print('family score:',tolstoy_lm.score('family'))\n",
    "print('family score:',wilde_lm.score('family'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e61a5e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1091\n",
      "1035\n",
      "1611\n",
      "820\n"
     ]
    }
   ],
   "source": [
    "# Test setting\n",
    "print(len(austen_test))\n",
    "print(len(dickens_test))\n",
    "print(len(tolstoy_test))\n",
    "print(len(wilde_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7aea8d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['<s>', 'Mr'], dtype='<U3'), array(['Mr', 'Suckling'], dtype='<U8'), array(['Suckling', 's'], dtype='<U8'), array(['s', 'seat'], dtype='<U4'), array(['seat', 'a'], dtype='<U4'), array(['a', 'comparison'], dtype='<U10'), array(['comparison', 'of'], dtype='<U10'), array(['of', 'Hartfield'], dtype='<U9'), array(['Hartfield', 'to'], dtype='<U9'), array(['to', 'Maple'], dtype='<U5'), array(['Maple', 'Grove'], dtype='<U5'), array(['Grove', 'The'], dtype='<U5'), array(['The', '</s>'], dtype='<U4')] 1091\n",
      "{'austen': 0.6342804766269478}\n",
      "[array(['<s>', 'like'], dtype='<U4'), array(['like', 'this'], dtype='<U4'), array(['this', 'It'], dtype='<U4'), array(['It', 'made'], dtype='<U4'), array(['made', 'me'], dtype='<U4'), array(['me', 'so'], dtype='<U2'), array(['so', 'sorry'], dtype='<U5'), array(['sorry', 'that'], dtype='<U5'), array(['that', 'I'], dtype='<U4'), array(['I', 'could'], dtype='<U5'), array(['could', 'only'], dtype='<U5'), array(['only', 'say'], dtype='<U4'), array(['say', 'in'], dtype='<U3'), array(['in', 'a'], dtype='<U2'), array(['a', 'foolish'], dtype='<U7'), array(['foolish', '</s>'], dtype='<U7')] 1035\n",
      "{'austen': 0.6342804766269478, 'dickens': 0.48792270531400966}\n",
      "[array(['<s>', 'herself'], dtype='<U7'), array(['herself', 'in'], dtype='<U7'), array(['in', 'supposing'], dtype='<U9'), array(['supposing', 'she'], dtype='<U9'), array(['she', 'could'], dtype='<U5'), array(['could', 'be'], dtype='<U5'), array(['be', 'what'], dtype='<U4'), array(['what', 'she'], dtype='<U4'), array(['she', 'wanted'], dtype='<U6'), array(['wanted', 'to'], dtype='<U6'), array(['to', 'be'], dtype='<U2'), array(['be', 'Her'], dtype='<U3'), array(['Her', 'eyes'], dtype='<U4'), array(['eyes', 'were'], dtype='<U4'), array(['were', '</s>'], dtype='<U4')] 1611\n",
      "{'austen': 0.6342804766269478, 'dickens': 0.48792270531400966, 'tolstoy': 0.6604593420235878}\n",
      "[array(['<s>', 'realising'], dtype='<U9'), array(['realising', 'it'], dtype='<U9'), array(['it', '</s>'], dtype='<U4')] 820\n",
      "{'austen': 0.6342804766269478, 'dickens': 0.48792270531400966, 'tolstoy': 0.6604593420235878, 'wilde': 0.47317073170731705}\n",
      "{'austen': 0.6342804766269478, 'dickens': 0.48792270531400966, 'tolstoy': 0.6604593420235878, 'wilde': 0.47317073170731705}\n",
      "1032\n"
     ]
    }
   ],
   "source": [
    "lst = [austen_test, dickens_test, tolstoy_test, wilde_test]\n",
    "results = {}\n",
    "INF = float('inf')\n",
    "infCount = 0\n",
    "\n",
    "for cur in range(len(lst)):\n",
    "#     infCount = 0\n",
    "    correct = 0\n",
    "    dev_set = lst[cur]\n",
    "    dev_set = list(map(test_mapping, dev_set))\n",
    "    print(dev_set[0], len(dev_set))\n",
    "    \n",
    "    for i in range(len(dev_set)):\n",
    "    #   Calculate perplexity\n",
    "        au = austen_lm.perplexity(dev_set[i])\n",
    "        di = dickens_lm.perplexity(dev_set[i])\n",
    "        to = tolstoy_lm.perplexity(dev_set[i])\n",
    "        wi = wilde_lm.perplexity(dev_set[i])\n",
    "        lowest = [au, di, to, wi]\n",
    "\n",
    "    #   get lowest idx\n",
    "        if (min(lowest) == INF):\n",
    "            infCount += 1\n",
    "            pass\n",
    "        else:\n",
    "            if (lowest.index(min(lowest)) == cur):\n",
    "                correct += 1\n",
    "     \n",
    "    if (cur == 0):\n",
    "        results['austen'] = correct/len(dev_set)\n",
    "        print(results)\n",
    "        \n",
    "    elif (cur == 1):\n",
    "        results['dickens'] = correct/len(dev_set)\n",
    "        print(results)\n",
    "\n",
    "    elif (cur == 2):\n",
    "        results['tolstoy'] = correct/len(dev_set)\n",
    "        print(results)\n",
    "\n",
    "    elif (cur == 3):\n",
    "        results['wilde'] = correct/len(dev_set)\n",
    "        print(results)\n",
    "\n",
    "print(results)\n",
    "print(infCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1c549bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('austen , perplexity:',round(austen_lm.perplexity(test), 1),', entropy:', round(austen_lm.entropy(test), 1))\n",
    "# print('dickens, perplexity:',round(dickens_lm.perplexity(test), 1),', entropy:', round(dickens_lm.entropy(test), 1))\n",
    "# print('tolstoy, perplexity:',round(tolstoy_lm.perplexity(test), 1),', entropy:', round(tolstoy_lm.entropy(test), 1))\n",
    "# print('wilde  , perplexity:',round(wilde_lm.perplexity(test), 1),', entropy:', round(wilde_lm.entropy(test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5db36e1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austen  : ['will', 'follow', 'it', 'had', 'somewhat', 'spent', 'ours', 'and', 'ate', 'the']\n",
      "Dickens : ['when', 'I', 'had', 'a', 'wall', '</s>', 'very', 'intimate', '</s>', 'a']\n",
      "Tolstoy : ['to', '</s>', 'and', 'in', 'law', 'was', '</s>', 'to', 'him', 'he']\n",
      "Wilde   : ['library', 'window', 'What', 'was', '</s>', '</s>', 'out', 'of', 'cruelty', 'downright']\n"
     ]
    }
   ],
   "source": [
    "random_seed = 10\n",
    "print('Austen  :', austen_lm.generate(10))\n",
    "print('Dickens :', dickens_lm.generate(10))\n",
    "print('Tolstoy :', tolstoy_lm.generate(10))\n",
    "print('Wilde   :', wilde_lm.generate(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ad1074e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.2\n",
      "40.4\n",
      "26.6\n",
      "47.4\n"
     ]
    }
   ],
   "source": [
    "test_au = austen_lm.generate(5, text_seed=['good'], random_seed=random_seed)\n",
    "test_di = dickens_lm.generate(5, text_seed=['good'], random_seed=random_seed)\n",
    "test_to = tolstoy_lm.generate(5, text_seed=['good'], random_seed=random_seed)\n",
    "test_wi = wilde_lm.generate(5, text_seed=['good'], random_seed=random_seed)\n",
    "\n",
    "\n",
    "\n",
    "# test_au = list(pad_both_ends(test_au, n=2))\n",
    "test_au = ngrams(test_au, n=2)\n",
    "# test_di = list(pad_both_ends(test_di, n=2))\n",
    "test_di = ngrams(test_di, n=2)\n",
    "test_to = list(pad_both_ends(test_to, n=2))\n",
    "test_to = ngrams(test_to, n=2)\n",
    "test_wi = list(pad_both_ends(test_wi, n=2))\n",
    "test_wi = ngrams(test_wi, n=2)\n",
    "\n",
    "print(round(austen_lm.perplexity(test_au), 1))\n",
    "print(round(dickens_lm.perplexity(test_di), 1))\n",
    "print(round(tolstoy_lm.perplexity(test_to), 1))\n",
    "print(round(wilde_lm.perplexity(test_wi), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a855df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288ea31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
